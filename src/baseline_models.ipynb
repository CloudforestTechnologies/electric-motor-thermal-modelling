{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Importations\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_motor_data():\n",
    "    \"\"\"Load Dataset\n",
    "    ======================================\n",
    "    Loads dataset from user-specified directory.\n",
    "    \n",
    "    Args:\n",
    "        None.\n",
    "        \n",
    "    Returns:\n",
    "        dataframe (dataframe) - Dataframe loaded with data from csv.\n",
    "    \"\"\"\n",
    "\n",
    "    file_string = r'C:\\Users\\ASUS-PC\\OneDrive\\Cloudforest Technologies\\M. Projects\\Yellow Cuckoo\\pmsm_temperature_data.csv'\n",
    "    return pd.read_csv(file_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "original_dataset = load_motor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    \"\"\"Split Training & Test Data\n",
    "    ======================================\n",
    "    Splits original dataset into training and evaluation data.\n",
    "    \n",
    "    Args:\n",
    "        data (dataframe) - Original test data.\n",
    "        test_ratio (int) - Ratio for splitting dataset as training percentage.\n",
    "        \n",
    "    Returns:\n",
    "        data_train (dataframe) - Dataframe with training data slice.\n",
    "        data_test (dataframe) - Dataframe with testing data slice.\n",
    "    \"\"\"\n",
    "\n",
    "    # Random seed setting ensures identical data split between calls\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "\n",
    "    # Create slices of test and training indices\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "training_set, test_set = split_train_test(original_dataset, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rotor target\n",
    "rotor_training_data = training_set.drop(\"pm\", axis = 1)\n",
    "rotor_label_data = training_set[\"pm\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36664bitd546b3131dc04b45b27adb02c244c21c",
   "display_name": "Python 3.6.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}