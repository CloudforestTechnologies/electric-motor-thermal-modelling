{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Module Importations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project Module Importations\n",
    "from src.data import load_data\n",
    "from src.data import split_data\n",
    "from src.models import keras_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "original_dataset = load_data.load_motor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training / evaluation sets\n",
    "training_set, evaluation_set = split_data.split_train_test(original_dataset, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ambient        coolant            u_d            u_q  \\\ncount  199614.000000  199614.000000  199614.000000  199614.000000   \nmean       -0.005043       0.005308       0.003792      -0.005359   \nstd         0.996490       1.002488       0.998747       1.001464   \nmin        -5.239872      -1.270450      -1.654002      -1.852853   \n25%        -0.601386      -1.037872      -0.831843      -0.924537   \n50%         0.266671      -0.178200       0.267391      -0.098490   \n75%         0.686838       0.673512       0.358587       0.848608   \nmax         2.954662       2.296845       2.273808       1.788773   \n\n         motor_speed         torque            i_d            i_q  \\\ncount  199614.000000  199614.000000  199614.000000  199614.000000   \nmean       -0.004852      -0.001687       0.004184      -0.001570   \nstd         1.001954       0.998525       0.999021       0.998389   \nmin        -1.353747      -3.339106      -3.235659      -3.329749   \n25%        -0.951892      -0.267419      -0.759524      -0.257273   \n50%        -0.140246      -0.186549       0.206151      -0.183473   \n75%         0.856986       0.548676       1.013975       0.501003   \nmax         2.024162       3.016479       1.060718       2.914179   \n\n                  pm    stator_yoke   stator_tooth  stator_winding  \ncount  199614.000000  199614.000000  199614.000000   199614.000000  \nmean       -0.004875       0.001077      -0.001664       -0.003221  \nstd         0.997822       1.002443       1.000849        0.998714  \nmin        -2.631581      -1.833552      -2.063137       -2.019349  \n25%        -0.677244      -0.747915      -0.761951       -0.725616  \n50%         0.095507      -0.057212       0.005475        0.008515  \n75%         0.682715       0.698267       0.772167        0.729825  \nmax         2.917456       2.443347       2.325405        2.633611  \n"
    }
   ],
   "source": [
    "# Drop profile id data column\n",
    "training_set = training_set.drop(\"profile_id\", axis = 1)\n",
    "print(training_set.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rotor target\n",
    "rotor_training_data = training_set.drop(\"pm\", axis = 1)\n",
    "rotor_label_data = training_set[\"pm\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create train and test arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(rotor_training_data, rotor_label_data, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[mlp nn] Training model ...\nTrain on 159691 samples, validate on 39923 samples\nEpoch 1/20\n159691/159691 [==============================] - 52s 328us/step - loss: 111.4795 - val_loss: 103.7016\nEpoch 2/20\n159691/159691 [==============================] - 58s 361us/step - loss: 102.4642 - val_loss: 240.3558\nEpoch 3/20\n159691/159691 [==============================] - 62s 391us/step - loss: 97.0250 - val_loss: 98.7385\nEpoch 4/20\n159691/159691 [==============================] - 63s 395us/step - loss: 94.8564 - val_loss: 93.9247\nEpoch 5/20\n159691/159691 [==============================] - 64s 402us/step - loss: 93.5171 - val_loss: 92.7087\nEpoch 6/20\n159691/159691 [==============================] - 62s 389us/step - loss: 93.4739 - val_loss: 90.4945\nEpoch 7/20\n159691/159691 [==============================] - 56s 349us/step - loss: 92.1522 - val_loss: 91.7284\nEpoch 8/20\n159691/159691 [==============================] - 52s 328us/step - loss: 92.1445 - val_loss: 93.6380\nEpoch 9/20\n159691/159691 [==============================] - 53s 334us/step - loss: 90.8068 - val_loss: 101.7839\nEpoch 10/20\n159691/159691 [==============================] - 57s 359us/step - loss: 89.5076 - val_loss: 101.4686\nEpoch 11/20\n159691/159691 [==============================] - 55s 345us/step - loss: 89.3536 - val_loss: 87.7672\nEpoch 12/20\n159691/159691 [==============================] - 53s 333us/step - loss: 88.3440 - val_loss: 87.5688\nEpoch 13/20\n159691/159691 [==============================] - 50s 313us/step - loss: 88.4648 - val_loss: 92.9489\nEpoch 14/20\n159691/159691 [==============================] - 39s 242us/step - loss: 87.8410 - val_loss: 88.2320\nEpoch 15/20\n159691/159691 [==============================] - 49s 304us/step - loss: 88.0092 - val_loss: 85.2779\nEpoch 16/20\n159691/159691 [==============================] - 53s 331us/step - loss: 86.4322 - val_loss: 88.2395\nEpoch 17/20\n159691/159691 [==============================] - 58s 360us/step - loss: 87.2095 - val_loss: 84.8763\nEpoch 18/20\n159691/159691 [==============================] - 58s 366us/step - loss: 86.9570 - val_loss: 92.0753\nEpoch 19/20\n159691/159691 [==============================] - 60s 373us/step - loss: 86.2486 - val_loss: 85.3174\nEpoch 20/20\n159691/159691 [==============================] - 53s 334us/step - loss: 86.0093 - val_loss: 82.2744\nmlp nn MSE: 0.7078754887956338\nmlp nn MAE: 0.5448311160735365\n"
    }
   ],
   "source": [
    "# Multilayer Perceptron (Target - Rotor Temperature)\n",
    "model_name = \"YC_0001\"\n",
    "\n",
    "# Clear existing models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Create model\n",
    "mlp_model = keras_helpers.create_multilayer_perceptron(X_train.shape[1])\n",
    "\n",
    "# Train model\n",
    "mlp_model = keras_helpers.train_multilayer_perceptron(mlp_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(model_name, \"MSE: \", str(rmse))\n",
    "print(model_name, \"MAE\", str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[mlp nn] Training model ...\nTrain on 159691 samples, validate on 39923 samples\nEpoch 1/20\n159691/159691 [==============================] - 24s 152us/step - loss: 147.2218 - val_loss: 154.0536\nEpoch 2/20\n159691/159691 [==============================] - 25s 154us/step - loss: 117.2198 - val_loss: 103.5536\nEpoch 3/20\n159691/159691 [==============================] - 27s 167us/step - loss: 105.5064 - val_loss: 108.1298\nEpoch 4/20\n159691/159691 [==============================] - 29s 180us/step - loss: 102.8424 - val_loss: 101.4977\nEpoch 5/20\n159691/159691 [==============================] - 26s 164us/step - loss: 99.7775 - val_loss: 106.6044\nEpoch 6/20\n159691/159691 [==============================] - 33s 208us/step - loss: 94.4717 - val_loss: 89.3976\nEpoch 7/20\n159691/159691 [==============================] - 28s 178us/step - loss: 91.0734 - val_loss: 95.8993\nEpoch 8/20\n159691/159691 [==============================] - 30s 185us/step - loss: 89.5184 - val_loss: 86.4464\nEpoch 9/20\n159691/159691 [==============================] - 26s 163us/step - loss: 89.0941 - val_loss: 85.8600\nEpoch 10/20\n159691/159691 [==============================] - 23s 146us/step - loss: 86.8433 - val_loss: 86.5202\nEpoch 11/20\n159691/159691 [==============================] - 21s 129us/step - loss: 85.1702 - val_loss: 84.9254\nEpoch 12/20\n159691/159691 [==============================] - 23s 142us/step - loss: 85.6062 - val_loss: 82.1771\nEpoch 13/20\n159691/159691 [==============================] - 26s 160us/step - loss: 84.6296 - val_loss: 84.1979\nEpoch 14/20\n159691/159691 [==============================] - 24s 149us/step - loss: 84.8306 - val_loss: 83.6561\nEpoch 15/20\n159691/159691 [==============================] - 24s 148us/step - loss: 83.2661 - val_loss: 81.7455\nEpoch 16/20\n159691/159691 [==============================] - 31s 194us/step - loss: 82.8775 - val_loss: 80.0608\nEpoch 17/20\n159691/159691 [==============================] - 24s 149us/step - loss: 82.5752 - val_loss: 86.7711\nEpoch 18/20\n159691/159691 [==============================] - 23s 141us/step - loss: 82.3292 - val_loss: 81.2700\nEpoch 19/20\n159691/159691 [==============================] - 22s 141us/step - loss: 81.0224 - val_loss: 78.3305\nEpoch 20/20\n159691/159691 [==============================] - 23s 144us/step - loss: 81.9560 - val_loss: 78.3561\nYC_00002 MSE:  0.6408119269954808\nYC_00002 MAE 0.49077063573844415\n"
    }
   ],
   "source": [
    "# Multilayer Perceptron (Target - Rotor Temperature)\n",
    "model_name = \"YC_0002\"\n",
    "\n",
    "# Clear existing models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Create model\n",
    "mlp_model = keras_helpers.create_multilayer_perceptron(X_train.shape[1])\n",
    "\n",
    "# Train model\n",
    "mlp_model = keras_helpers.train_multilayer_perceptron(mlp_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(model_name, \"MSE: \", str(rmse))\n",
    "print(model_name, \"MAE\", str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input Dimension: 11\n[mlp nn] Training model ...\nTrain on 159691 samples, validate on 39923 samples\nEpoch 1/20\n159691/159691 [==============================] - 24s 151us/step - loss: 0.1882 - val_loss: 0.1562\nEpoch 2/20\n159691/159691 [==============================] - 23s 141us/step - loss: 0.1499 - val_loss: 0.1577\nEpoch 3/20\n159691/159691 [==============================] - 20s 122us/step - loss: 0.1392 - val_loss: 0.1352\nEpoch 4/20\n159691/159691 [==============================] - 23s 147us/step - loss: 0.1325 - val_loss: 0.1309\nEpoch 5/20\n159691/159691 [==============================] - 22s 140us/step - loss: 0.1292 - val_loss: 0.1280\nEpoch 6/20\n159691/159691 [==============================] - 20s 124us/step - loss: 0.1258 - val_loss: 0.1342\nEpoch 7/20\n159691/159691 [==============================] - 24s 153us/step - loss: 0.1231 - val_loss: 0.1195\nEpoch 8/20\n159691/159691 [==============================] - 22s 136us/step - loss: 0.1212 - val_loss: 0.1157\nEpoch 9/20\n159691/159691 [==============================] - 23s 146us/step - loss: 0.1195 - val_loss: 0.1188\nEpoch 10/20\n159691/159691 [==============================] - 21s 133us/step - loss: 0.1181 - val_loss: 0.1163\nEpoch 11/20\n159691/159691 [==============================] - 22s 139us/step - loss: 0.1170 - val_loss: 0.1201\nEpoch 12/20\n159691/159691 [==============================] - 25s 159us/step - loss: 0.1157 - val_loss: 0.1126\nEpoch 13/20\n159691/159691 [==============================] - 25s 158us/step - loss: 0.1145 - val_loss: 0.1302\nEpoch 14/20\n159691/159691 [==============================] - 22s 138us/step - loss: 0.1136 - val_loss: 0.1689\nEpoch 15/20\n159691/159691 [==============================] - 25s 157us/step - loss: 0.1127 - val_loss: 0.1098\nEpoch 16/20\n159691/159691 [==============================] - 22s 135us/step - loss: 0.1117 - val_loss: 0.1142\nEpoch 17/20\n159691/159691 [==============================] - 25s 156us/step - loss: 0.1110 - val_loss: 0.1109\nEpoch 18/20\n159691/159691 [==============================] - 24s 153us/step - loss: 0.1101 - val_loss: 0.1143\nEpoch 19/20\n159691/159691 [==============================] - 23s 141us/step - loss: 0.1095 - val_loss: 0.1074\nEpoch 20/20\n159691/159691 [==============================] - 22s 138us/step - loss: 0.1090 - val_loss: 0.1115\nYC_0003 MSE:  0.33384361303991167\nYC_0003 MAE 0.24620932729992528\n"
    }
   ],
   "source": [
    "# Multilayer Perceptron (Target - Rotor Temperature)\n",
    "model_name = \"YC_0003\"\n",
    "\n",
    "# Clear existing models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Create model\n",
    "mlp_model = keras_helpers.create_multilayer_perceptron(X_train.shape[1])\n",
    "\n",
    "# Train model\n",
    "mlp_model = keras_helpers.train_multilayer_perceptron(mlp_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(model_name, \"MSE: \", str(rmse))\n",
    "print(model_name, \"MAE\", str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input Dimension: 11\n[mlp nn] Training model ...\nTrain on 159691 samples, validate on 39923 samples\nEpoch 1/20\n159691/159691 [==============================] - 30s 189us/step - loss: 0.1641 - val_loss: 0.2332\nEpoch 2/20\n159691/159691 [==============================] - 32s 202us/step - loss: 0.1214 - val_loss: 0.1159\nEpoch 3/20\n159691/159691 [==============================] - 33s 204us/step - loss: 0.1063 - val_loss: 0.0990\nEpoch 4/20\n159691/159691 [==============================] - 28s 175us/step - loss: 0.0973 - val_loss: 0.1348\nEpoch 5/20\n159691/159691 [==============================] - 30s 188us/step - loss: 0.0904 - val_loss: 0.1009\nEpoch 6/20\n159691/159691 [==============================] - 24s 152us/step - loss: 0.0856 - val_loss: 0.0808\nEpoch 7/20\n159691/159691 [==============================] - 28s 177us/step - loss: 0.0812 - val_loss: 0.0841\nEpoch 8/20\n159691/159691 [==============================] - 24s 150us/step - loss: 0.0778 - val_loss: 0.0764\nEpoch 9/20\n159691/159691 [==============================] - 24s 153us/step - loss: 0.0745 - val_loss: 0.0809\nEpoch 10/20\n159691/159691 [==============================] - 26s 165us/step - loss: 0.0716 - val_loss: 0.0779\nEpoch 11/20\n159691/159691 [==============================] - 23s 145us/step - loss: 0.0695 - val_loss: 0.0763\nEpoch 12/20\n159691/159691 [==============================] - 26s 164us/step - loss: 0.0673 - val_loss: 0.0663\nEpoch 13/20\n159691/159691 [==============================] - 26s 166us/step - loss: 0.0653 - val_loss: 0.0660\nEpoch 14/20\n159691/159691 [==============================] - 30s 185us/step - loss: 0.0635 - val_loss: 0.0690\nEpoch 15/20\n159691/159691 [==============================] - 30s 185us/step - loss: 0.0621 - val_loss: 0.0631\nEpoch 16/20\n159691/159691 [==============================] - 26s 160us/step - loss: 0.0606 - val_loss: 0.0604\nEpoch 17/20\n159691/159691 [==============================] - 30s 187us/step - loss: 0.0595 - val_loss: 0.0586\nEpoch 18/20\n159691/159691 [==============================] - 29s 180us/step - loss: 0.0581 - val_loss: 0.0570\nEpoch 19/20\n159691/159691 [==============================] - 27s 167us/step - loss: 0.0569 - val_loss: 0.0622\nEpoch 20/20\n159691/159691 [==============================] - 27s 172us/step - loss: 0.0560 - val_loss: 0.0561\nYC_0004 MSE:  0.23690404220187172\nYC_0004 MAE 0.16893484381165494\nYC_0004 MAE 0.16893484381165494\n"
    }
   ],
   "source": [
    "# Multilayer Perceptron (Target - Rotor Temperature)\n",
    "model_name = \"YC_0004\"\n",
    "\n",
    "# Clear existing models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Create model\n",
    "mlp_model = keras_helpers.create_multilayer_perceptron(X_train.shape[1])\n",
    "\n",
    "# Train model\n",
    "mlp_model = keras_helpers.train_multilayer_perceptron(mlp_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(model_name, \"MSE: \", str(rmse))\n",
    "print(model_name, \"MAE\", str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron (Target - Rotor Temperature)\n",
    "model_name = \"YC_0005\"\n",
    "\n",
    "# Clear existing models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Create model\n",
    "mlp_model = keras_helpers.create_multilayer_perceptron(X_train.shape[1])\n",
    "\n",
    "# Train model\n",
    "mlp_model = keras_helpers.train_multilayer_perceptron(mlp_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(model_name, \"MSE: \", str(rmse))\n",
    "print(model_name, \"MAE\", str(mae))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594888778096",
   "display_name": "Python 3.6.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}